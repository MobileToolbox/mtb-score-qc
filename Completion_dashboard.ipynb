{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liked-customs",
   "metadata": {
    "tags": [
     "remove_cell"
    ]
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import synapseclient\n",
    "import pylab as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "import ipywidgets as widgets\n",
    "# %matplotlib widget #breaks javascript in notebook\n",
    "\n",
    "import create_summary\n",
    "\n",
    "COMPLETION_COLS = ['wasCompleted', 'inSynapseParent', 'inStudyProject', 'inParquet', 'inScores']\n",
    "DELTA_T_COLS = ['completion time [s]', 'export delay [s]', 'upload delay [s]', 'in Synapse delay [s]']\n",
    "\n",
    "syn = synapseclient.login();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "absent-cuisine",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Load Data \n",
    "studies = create_summary.getStudies(syn)\n",
    "df = pd.read_csv(syn.get('syn51185576').path, low_memory=False)\n",
    "timeCols =  ['uploadedOn', 'finishedOn', 'startedOn', 'eventTimestamp_x', 'modifiedOn', 'createdOn', 'exportedOn', 'eventTimestamp_y']\n",
    "df[timeCols] = df[timeCols].apply(pd.to_datetime)\n",
    "\n",
    "#Fill in startedOn data for columns and remove fnamea\n",
    "df = (df.assign(startedOn = np.where(df.startedOn.isnull(), df.uploadedOn, df.startedOn))\n",
    "      .query(\"assessmentId!='fnamea'\")\n",
    "      .set_index('startedOn', drop=True))\n",
    "\n",
    "df['completion time [s]'] = (df.finishedOn-df.index).map(lambda x:x.seconds)\n",
    "df['export delay [s]'] = (df.exportedOn-df.finishedOn).map(lambda x:x.seconds)\n",
    "df['upload delay [s]'] = (df.uploadedOn-df.finishedOn).map(lambda x:x.seconds)\n",
    "df['in Synapse delay [s]'] = (df.createdOn-df.finishedOn).map(lambda x:x.seconds)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sudden-healthcare",
   "metadata": {},
   "source": [
    "# Percent complete Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "asian-average",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "temp_df = df.dropna(subset=['wasCompleted'])[COMPLETION_COLS]\n",
    "n_alltime = temp_df.sum()\n",
    "pct_alltime = pd.DataFrame(n_alltime.div(n_alltime['wasCompleted'], axis=0)*100, columns=['All Time'])\n",
    "labels_alltime = pd.DataFrame([f\"{a:.0f}%\\n\\nn={b:,.0f}\" for a, b in zip(pct_alltime['All Time'], n_alltime)])\n",
    "\n",
    "plt.figure(figsize=(13,3))\n",
    "#ax = sns.heatmap(pct_alltime.T, annot=True, fmt=\".0f\", cbar=False, linewidth=5, vmin=0);\n",
    "ax = sns.heatmap(pct_alltime.T, annot=labels_alltime.T, fmt=\"s\", cbar=False, linewidth=5, vmin=0,\n",
    "                annot_kws={\"fontsize\":22});\n",
    "plt.yticks([])\n",
    "plt.title('All Time', fontsize=22);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coral-harbor",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "n_lastweek = temp_df.groupby(pd.Grouper(freq='W')).sum().iloc[-2]\n",
    "legend = n_lastweek.name.strftime('week of %d-%b-%Y')\n",
    "n_lastweek.name = legend\n",
    "pct_lastweek  = pd.DataFrame(n_lastweek.div(n_lastweek['wasCompleted'], axis=0)*100)\n",
    "labels_lastweek = pd.DataFrame([f\"{a:.0f}%\\n\\nn={b:,.0f}\" for a, b in zip(pct_lastweek[legend], n_lastweek)])\n",
    "\n",
    "#n_lastweek\n",
    "plt.figure(figsize=(13,3))\n",
    "#ax = sns.heatmap(pct_lastweek.T, annot=True, fmt=\".0f\", cbar=False, linewidth=5,vmin=0);\n",
    "ax = sns.heatmap(pct_lastweek.T, annot=labels_lastweek.T, fmt=\"s\", cbar=False, linewidth=5, vmin=0,\n",
    "                annot_kws={\"fontsize\":22});\n",
    "plt.yticks([])\n",
    "plt.title(legend, fontsize=22);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "personal-earthquake",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "n_lastweek = temp_df.groupby(pd.Grouper(freq='W')).sum().iloc[-1]\n",
    "legend = n_lastweek.name.strftime('week of %d-%b-%Y')\n",
    "n_lastweek.name = legend\n",
    "pct_lastweek  = pd.DataFrame(n_lastweek.div(n_lastweek['wasCompleted'], axis=0)*100)\n",
    "labels_lastweek = pd.DataFrame([f\"{a:.0f}%\\n\\nn={b:,.0f}\" for a, b in zip(pct_lastweek[legend], n_lastweek)])\n",
    "\n",
    "#n_lastweek\n",
    "plt.figure(figsize=(13,3))\n",
    "#ax = sns.heatmap(pct_lastweek.T, annot=True, fmt=\".0f\", cbar=False, linewidth=5,vmin=0);\n",
    "ax = sns.heatmap(pct_lastweek.T, annot=labels_lastweek.T, fmt=\"s\", cbar=False, linewidth=5, vmin=0,\n",
    "                annot_kws={\"fontsize\":22});\n",
    "plt.yticks([])\n",
    "plt.title(legend, fontsize=22);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "russian-specialist",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,4))\n",
    "ax = plt.subplot(1,1,1)\n",
    "(df.query(\"wasCompleted==1\").groupby(pd.Grouper(freq='W'))[COMPLETION_COLS].mean()*100).plot(ax=ax)\n",
    "plt.title('Data Status Across Time')\n",
    "plt.ylim(0,102)\n",
    "plt.ylabel('completed [%]');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "separated-filing",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,5))\n",
    "for i, label in enumerate(['assessmentId','studyId','osName']):\n",
    "    ax = plt.subplot(1,3,i+1)\n",
    "    (df.query(\"wasCompleted==1& osName!='Linux'\").groupby(label)[COMPLETION_COLS].mean()*100).plot(ax=ax, legend=False)\n",
    "    plt.ylabel('Available [%]')\n",
    "    plt.title(label)\n",
    "    plt.ylim(0,102)\n",
    "    plt.xticks(rotation = 45, ha='right')\n",
    "plt.legend()\n",
    "plt.suptitle('Factors Affecting completeness', fontsize=22);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "agreed-economics",
   "metadata": {},
   "source": [
    "## Associations between missing data and conditions when collected\n",
    "Evaluates whether there are any specific conditions that lead to a higher risk of missing data. For example whether the appVersion or the date is assoicated with data being missing in the **scores**. Can also be modified to identify other missingness for example in upload or parquet data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "upper-producer",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "#Columns that are evaluated\n",
    "correlated_columns=['assessmentId', 'studyId', 'appVersion','assessmentRevision', 'clientTimeZone', 'declined', \n",
    "                    'deviceName', 'languages','osName', 'osVersion', 'scheduleGuid', 'sessionGuid', \n",
    "                    'sessionInstanceGuid', 'sessionInstanceStartDay', 'sessionStartEventId', 'sharingScope']\n",
    "\n",
    "@widgets.interact(stage_missing=['inScores', 'inParquet', 'inStudyProject'], \n",
    "                  end_date = df.index.max().strftime('%Y-%m-%d %X'),\n",
    "                  p_cut_off=widgets.fixed(1e-3))\n",
    "def find_correlated_variables(start_date='2023-03-01 00:00:00', end_date='2023-04-01 00:00:00', stage_missing='inScores', p_cut_off=0.001):\n",
    "    \"\"\"Filters the data by timeframe and compares the differences in missingness in a specific stage in\n",
    "       pipeline.  Computes contigency tables and determines if differences are statistically significant and plot\n",
    "       the odds of missing data.\n",
    "       \n",
    "    \"\"\"\n",
    "    temp_df = df[df.index > start_date].query('wasCompleted==1')\n",
    "    temp_df = temp_df[temp_df.index<end_date]\n",
    "    for variable in correlated_columns:\n",
    "\n",
    "        #Create contigency table\n",
    "        contigency = (temp_df[[stage_missing, variable]]\n",
    "             .groupby(variable)[stage_missing]\n",
    "             .value_counts()  #Count number of missing and nn missing\n",
    "             .to_frame(name='available')      \n",
    "             .reset_index(1)\n",
    "             .pivot_table(columns=stage_missing, values='available', index=variable)\n",
    "             .fillna(0)  #If there are no counts set the NaN to 0\n",
    "             .rename(columns={1.0:'Present', 0.0:'Missing'})\n",
    "        )\n",
    "        # Filtering out any categories with too few measurements \n",
    "        contigency = contigency[contigency.sum(axis=1)>10]\n",
    "        # Only continue of data is missing\n",
    "        if 'Missing' not in contigency.columns:\n",
    "            continue\n",
    "        # Compute Chi-square statistic for missingness being different between groups\n",
    "        # Assumption there is no relationship between variable and missingness\n",
    "        chi2, p, dof, expected = stats.chi2_contingency(contigency)\n",
    "    \n",
    "        # odds of missing data = (# 0s)/(# 1s)\n",
    "        contigency['Odds']=contigency['Missing']/contigency['Present']\n",
    "    \n",
    "        #Plot odds of missingness for each category if the p-value<0.001\n",
    "        if p<p_cut_off:\n",
    "            plt.figure(figsize=(13,6))\n",
    "            ax=plt.subplot(2,1,1)\n",
    "            contigency.plot(y='Odds', kind='bar', ax=ax);\n",
    "            plt.ylabel('Odds of Missing')\n",
    "            plt.title('%s p=%0.2g' %(variable, p))\n",
    "            ax=plt.subplot(2,1,2)\n",
    "            #Format table for display\n",
    "            contigency['Odds'] = contigency['Odds'].apply('{:,.1f}'.format)\n",
    "            contigency = contigency.astype({'Present': int, 'Missing': int})\n",
    "            plt.table(cellText=contigency.values.T, colLabels=contigency.index, rowLabels=contigency.columns, loc='center')\n",
    "            plt.axis('off');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "residential-setup",
   "metadata": {},
   "source": [
    "## Study Specific information\n",
    "Filter down to a specific study and explore the data within that study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "raising-dating",
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = df.groupby('studyId')\n",
    "@widgets.interact(study=groups.groups.keys())\n",
    "def plot_studies(study):\n",
    "    plt.figure(figsize=(2,8))\n",
    "    temp_df = groups.get_group(study)[COMPLETION_COLS]\n",
    "    ax = plt.subplot(1,1,1)\n",
    "    sns.heatmap(temp_df, cbar=False, ax=ax)\n",
    "    ticklabels = ['NaT' if pd.isnull(temp_df.index[int(tick)]) else temp_df.index[int(tick)].strftime('%Y-%m-%d') for tick in ax.get_yticks()]\n",
    "    ax.set_yticklabels(ticklabels);\n",
    "    label = (studies.query(\"studyId=='%s'\"%study)['name']+'('+ studies.query(\"studyId=='%s'\"%study)['id'] + ')').iloc[0]\n",
    "    plt.title(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ethical-steam",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "@widgets.interact(study=groups.groups.keys(), stages=COMPLETION_COLS )\n",
    "def show_participant_level_data(study='hktrrx', stages='inStudyProject'):\n",
    "    return (df.query(\"studyId=='%s'\" %study)\n",
    "           .groupby(['externalId', 'sessionGuid'])[stages]\n",
    "           .apply(sum).reset_index()\n",
    "           .pivot(index='externalId', columns='sessionGuid')\n",
    "           .fillna(0)\n",
    "           .astype(int))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "synthetic-nursing",
   "metadata": {},
   "source": [
    "## Timing information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expired-authorization",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "    \n",
    "timing = df.groupby(pd.Grouper(freq='W'))[DELTA_T_COLS].median()\n",
    "sns.lineplot(data=timing)\n",
    "plt.ylabel('Delay [s]');\n",
    "plt.yscale('log')\n",
    "timing = timing.reset_index().melt(id_vars=['startedOn'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (global)",
   "language": "python",
   "name": "py3global"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
